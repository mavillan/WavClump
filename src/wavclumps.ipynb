{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <h1> INF491 - Astroinformatics </h1>\n",
    "    <h2> WavClumps Project:  A Wavelet based algorithm to find clumps and its structure </h2>\n",
    "    <h3> Martín Villanueva A. <sup>1</sup></h3>\n",
    "</center>\n",
    "\n",
    "[1] _martin.villanueva@alumnos.usm.cl - DI UTFSM - June 2016._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "* [Introduction](#intro)\n",
    "* [Proposed Solution](#proposal)\n",
    "* [Concept Test and Experiments](#tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='intro' />\n",
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In concise words the problem to be addressed consists on given a 3D spectroscopic cube of data (mostly from observations of cold molecular clouds), build an algorithm that automatically can identify clump structures, and determine the hierarchical relationships between them. **Why?**\n",
    "\n",
    "* Manual methods **doesn’t scale** as fast as the generation of new data observations.\n",
    "* Size of the images is **huge** and could contain hundreds/thousands of cores.\n",
    "* Clump identification performed (manually) by astronomers usually didn’t match (**biased methods**).\n",
    "* Determine the hierarchical relationships between the found clumps is fundamental to understand processes like the **star formation**.\n",
    "* Clumping algorithms **(GaussClump, ClumpFind, FellWalker)** do not face the problem of finding hierarchical structures.\n",
    "* State of the Art algorithm that that face this problem (Gregorio et al.) have only worked with **2D data** (collapsed cubes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='proposal' />\n",
    "## Proposed Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The proposed approach is the natural extension of Gregorio et al. to 3D spectroscopic data cubes. The solution outline of the methods is shown in the next image:\n",
    "<img src=\"files/wavclump.png\" style=\"width: 500px;\">\n",
    "As you can see, it corresponds to a **multi-stage** algorithm with the following steps:\n",
    "\n",
    "1. *Multiresolution Analysis* (**MRA**) is performed through a 3D Discrete Wavelet Transform (**3D-DWT**), to extract the features at different scales/frequencies.\n",
    "2. For each computed cube approximation a 3D clump *identification/segmentation* algorithm is applied, in order to find structures on each level.\n",
    "3. The results of each level will be (in some way) linked, according to his hierarchical structure. This will be summarized in a *tree structure* like a **Dendrogram**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Multiresolution Analysis through 3D-DWT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MRA is achieved by computing the 3D-DWT for the data cube at different levels, and then reconstructing the image with the approximation coefficients obtained at each level.\n",
    "\n",
    "**1) 1D-DWT.** Starting from a signal s of length N, two sets of coefficients are computed: approximation coefficients CA1, and detail coefficients CD1. These vectors are obtained by convolving s with the low-pass filter Lo_D for approximation and with the high-pass filter Hi_D for detail, followed by *dyadic decimation*.\n",
    "<img src=\"files/1Ddwt.gif\" style=\"width: 500px;\">\n",
    "\n",
    "**2) 2D-DWT.** This two-dimensional DWT leads to a decomposition of approximation coefficients at level j in four components: the _approximation_ at level j + 1, and the details in three orientations (_horizontal_, _vertical_, and _diagonal_). The following chart describes the basic decomposition steps for images:\n",
    "<img src=\"files/2Ddwt.gif\" style=\"width: 500px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Clump indentification/segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform this step two classic algorithms will be used:\n",
    "1. **ClumpFind.** The algorithm works by contouring the data at multiples of the rms noise of the observations. It starts from the highest level, where isolate cores are identified and each of these is considered as new clump. Then this step is repeated by gradually decreasing the level where to search, identifying isolate structures and connecting them with clumps identified at previous levels, or defining them as new clumps otherwise.\n",
    "<img src=\"files/cf.png\" style=\"width: 300px;\">\n",
    "\n",
    "2. **FellWalker.** The algorithms works by computing ascent paths (with the highest gradient) for each single pixel. These paths have two alternatives: 1) Reach a local peak and so find a new clump. 2) Reach another ascent path computed previously, and so assign the pixels on that path to the corresponding (crashed) clump.\n",
    "<img src=\"files/fw.png\" style=\"width: 300px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation.** An important feature must be taken into account: At higher levels (and lower frequencies) the resulting images are **much more easy/trivial to segmentate!**. Let's see for example, the MRA performed over a FITS image of Orion Methanol observations (slices at frequencies are shown).\n",
    "\n",
    "**Level 0** (no MRA)\n",
    "<img src=\"files/level0.png\" style=\"width: 800px;\">\n",
    "**Level 1**\n",
    "<img src=\"files/level1.png\" style=\"width: 800px;\">\n",
    "**Level 2**\n",
    "<img src=\"files/level2.png\" style=\"width: 800px;\">\n",
    "**Level 3**\n",
    "<img src=\"files/level3.png\" style=\"width: 800px;\">\n",
    "it is clear that in the high levels the clump structures are much more easy to identify that the ones in lower levels. **Then simpler algorithms could be used!** as those of *computer vision/image processing*: **Simple Thresholding**, **Watershed algorithm**, etc. The only **complication** is that (some of them) must be **adapted** for 3D data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Hierarchical relations\n",
    "In order to determine how clumps at different levels are related to each other, the following methods could be used:\n",
    "1. If the max pixel of a clump in the level $i$ it's contained on a clump at level $i+1$, then we say we say that clump al level $i$ proceeds from the corresponding clump at level $i+1$.\n",
    "2. The other alternative is to find the **center of mass** of clump at level $i$, and similarly if it is contained on a clump at level $i+1$, then the relationship is inferred.\n",
    "The results of such process are summarized in a tree-like structure (Dendrogram)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id='tests' />\n",
    "## Concept Test and Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import matplotlib.pyplot as plt\n",
    "import matlab.engine\n",
    "\n",
    "sys.path.append('../../ACALIB/')\n",
    "from acalib import acontainer as ac\n",
    "from acalib.io import graph as gp\n",
    "\n",
    "\n",
    "sys.path.insert(0, './clumping')\n",
    "import fellwalker as fwalker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matlab engine to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eng = matlab.engine.start_matlab()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing some wavelets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In first place let's see the efects of applying 3D-DWT on a FITS image to perform multiresolution analysis, with different Wavelets families. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eng.wavemenu(nargout=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading FITS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Loading data\n",
    "\"\"\"\n",
    "#fits_path = '../../bindata/fits/cubes/Antennae_North.CO3_2Line.Clean.pcal1.image.fits'\n",
    "#fits_path = '../../bindata/fits/cubes/Antennae_South.CO3_2Line.Clean.pcal1.image.fits'\n",
    "#fits_path = '../../bindata/fits/cubes/CenA.CO2_1Line.Clean.image.fits'\n",
    "#fits_path = '../../bindata/fits/cubes/M100line.image.fits'\n",
    "fits_path = '../../bindata/fits/cubes/Orion.methanol.cbc.contsub.image.fits'\n",
    "\n",
    "if os.path.isfile(fits_path):\n",
    "    ml_data = eng.load_fits(fits_path)\n",
    "    np_data = np.asarray(ml_data)\n",
    "    np_data = ma.masked_array(np_data, mask=np.isnan(np_data))\n",
    "else: print(\"FITS file doesn't exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A,D = eng.mra(ml_data, 'sym5', 3, nargout=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: CAA initialized successfully [fellwalker]\n",
      "INFO: [Stage 1] Removing small isolated regions [fellwalker]\n",
      "INFO: [Stage 2] Walking up! [fellwalker]\n"
     ]
    }
   ],
   "source": [
    "fw = fwalker.FellWalker()\n",
    "caa,clump = fw.run(np_data, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class WavClumps():\n",
    "    def __init__(self, wavelet='sym5', nlevel=4, clumping_method='fellwalker'):\n",
    "        self.wavelet = wavelet\n",
    "        self.nlevel = nlevel\n",
    "        #setting the clumping algorithm\n",
    "        if clumping_method=='fellwalker':\n",
    "            self.clumping = fwalker.FellWalker()\n",
    "        elif clumping_method=='clumpfind':\n",
    "            pass\n",
    "        #setting default params\n",
    "        self.default_params()\n",
    "    \n",
    "    def default_params(self):\n",
    "        pass\n",
    "    \n",
    "    def mra(self, ml_data):\n",
    "        \"\"\"\n",
    "        Computes approximations and details for each level\n",
    "        \"\"\"\n",
    "        _A,_D = eng.mra(ml_data, self.wavelet, self.nlevel, nargout=2)\n",
    "        \n",
    "        #casting to numpy.ndarray\n",
    "        A = map(np.asarray, _A)\n",
    "        D = map(np.asarray, _D)\n",
    "        del _A,_D\n",
    "        return (A,D)\n",
    "    \n",
    "    def dendro_build(self):\n",
    "        pass\n",
    "    \n",
    "    def run(self, np_data, ml_data):\n",
    "        #perform multiresolution analysis\n",
    "        A,D = self.mra(ml_data)\n",
    "        A.insert(0, np_data)\n",
    "        \n",
    "        #perform clumping algorithm over original data and each approximation level\n",
    "        caa = list()\n",
    "        clumps = list()\n",
    "        for data in A:\n",
    "            res = self.clumping.run(data)\n",
    "            caa.append(res[0])\n",
    "            clumps.append(res[1])\n",
    "        \n",
    "        #storing results\n",
    "        self.caa = caa\n",
    "        self.clumps = clumps\n",
    "        return caa,clumps\n",
    "    \n",
    "    def summarize(self):\n",
    "        for i in range(self.nlevel+1):\n",
    "            print('Level {0}:'.format(i))\n",
    "            print('Number of clumps: {0}'.format(len(self.clumps[i])))\n",
    "            mval = 0\n",
    "            for pixels in self.clumps[i].values():\n",
    "                npix = len(pixels)\n",
    "                if npix>mval: mval = npix\n",
    "            print('Number of pixels of bigger clump:{0}'.format(mval))\n",
    "            print('------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instances with differente Wavelet family "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wc1 = WavClumps(wavelet='haar', nlevel=4)\n",
    "wc2 = WavClumps(wavelet='db2', nlevel=4)\n",
    "wc3 = WavClumps(wavelet='sym3', nlevel=4)\n",
    "wc4 = WavClumps(wavelet='bior4.4', nlevel=4)\n",
    "wc5 = WavClumps(wavelet='rbio4.4', nlevel=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "caa1, clumps1 = wc1.run(np_data, ml_data)\n",
    "caa2, clumps2 = wc2.run(np_data, ml_data)\n",
    "caa3, clumps3 = wc3.run(np_data, ml_data)\n",
    "caa4, clumps4 = wc4.run(np_data, ml_data)\n",
    "caa5, clumps5 = wc5.run(np_data, ml_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Dictionary to handle results\n",
    "\"\"\"\n",
    "caa = {'haar':caa1, 'db2':caa2, 'sym3':caa3, 'bior4.4':caa4, 'rbio4.4':caa5}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some sumarizing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Haar wavelet\n",
    "\"\"\"\n",
    "wc1.summarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Daubechies wavelet\n",
    "\"\"\"\n",
    "wc2.summarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Near symmetric wavelet\n",
    "\"\"\"\n",
    "wc3.summarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Biorthogonal wavelet\n",
    "\"\"\"\n",
    "wc4.summarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Reverse biorthogonal wavelet\n",
    "\"\"\"\n",
    "wc5.summarize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some 2D graphical results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_caa_slices(caa, level, dslc=10):\n",
    "    caa = np.copy(caa)\n",
    "    caa[caa==-1] = 0\n",
    "    maxf = caa.shape[2]\n",
    "    idx_slices = np.linspace(dslc,maxf-dslc,9, dtype=np.int)\n",
    "    plt.figure(figsize=(15,15))\n",
    "    for i in range(9):\n",
    "        f = idx_slices[i]\n",
    "        plt.subplot(3,3,i+1)\n",
    "        plt.imshow(caa[:,:,f])\n",
    "        plt.xlabel('Freq = {0}'.format(f))\n",
    "        if i==1:\n",
    "            plt.title('CAA slices at level {0}'.format(level))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "level = 1\n",
    "show_caa_slices(caa['bior4.4'][level], level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some 3D graphical results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "Cube where to load CAAs\n",
    "\"\"\"\n",
    "cont=ac.AContainer()\n",
    "cont.load('../../bindata/fits/cubes/Orion.methanol.cbc.contsub.image.fits')\n",
    "cube=cont.primary.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "level = 2\n",
    "cube.data = caa['haar'][level]\n",
    "gp.volume(cube)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
